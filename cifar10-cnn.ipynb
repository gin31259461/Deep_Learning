{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CNN model for CIFAR-10 - Object Recognition in Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Cifar-10 Benchmark](https://paperswithcode.com/sota/image-classification-on-cifar-10)\n",
        "\n",
        "Ref.\n",
        "\n",
        "[CIFAR 10- CNN using PyTorch](https://www.kaggle.com/code/shadabhussain/cifar-10-cnn-using-pytorch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Python version: 3.10.6\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, v2\n",
        "import keras\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.keras import TqdmCallback\n",
        "\n",
        "tf.config.list_physical_devices(\"GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = \"final\"\n",
        "augmentation = False\n",
        "training = False\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "validation_split = 0.1 if training else 0.0\n",
        "output_filename = \"output-summary-{0}.txt\".format(version)\n",
        "feature = [\"batch normalization\", \"dropout\", \"add more layers\", \"fit all training data with no validation split\"]\n",
        "# feature = [\"batch normalization\", \"dropout\", \"add more layers\", \"image augmentation\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using pytorch utils to load dataset\n",
        "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "\n",
        "training_data = datasets.CIFAR10(\"data\", train=True, download=True, transform=ToTensor())\n",
        "test_data = datasets.CIFAR10(\"data\", train=False, download=True, transform=ToTensor())\n",
        "\n",
        "class_names = training_data.classes\n",
        "print(\"Class names of images: \", class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_images: np.ndarray = training_data.data\n",
        "test_images: np.ndarray = test_data.data\n",
        "\n",
        "train_labels = training_data.targets\n",
        "test_labels = test_data.targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_cifar10_images(images, n):\n",
        "    plt.figure(figsize=[10, 10])\n",
        "\n",
        "    for i in range(n):\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
        "        plt.xlabel(class_names[train_labels[i]])\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_cifar10_images(train_images, 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"train images shape: \", train_images.shape)\n",
        "print(\"train labels size: \", len(train_labels))\n",
        "print(\"test images shape: \", test_images.shape)\n",
        "print(\"test labels size: \", len(test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Image augmentation\n",
        "# Ref. https://www.kaggle.com/code/vikasbhadoria/cifar10-high-accuracy-model-build-on-pytorch\n",
        "# Ref. https://pytorch.org/vision/stable/transforms.html\n",
        "\n",
        "if augmentation:\n",
        "    transform_train_image = v2.Compose(\n",
        "        [\n",
        "            v2.ToImage(),\n",
        "            v2.Resize((32, 32)),  # resises the image so it can be perfect for our model.\n",
        "            v2.RandomHorizontalFlip(p=0.5),  # FLips the image w.r.t horizontal axis\n",
        "            v2.RandomRotation(10),  # Rotates the image to a specified angel\n",
        "            v2.RandomAffine(0, shear=10, scale=(0.8, 1.2)),  # Performs actions like zooms, change shear angles.\n",
        "            v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Set the color params\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_images_augmentation = np.array([transform_train_image(train_images[i]) for i in range(len(train_images))])\n",
        "\n",
        "    train_images_augmentation = train_images_augmentation.transpose((0, 2, 3, 1))\n",
        "\n",
        "    print(train_images_augmentation.shape)\n",
        "    plot_cifar10_images(train_images_augmentation, 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Join augmented images to train images & do normalization\n",
        "# Append train labels due to train images augmentation & one-hot encode labels\n",
        "\n",
        "\n",
        "if augmentation:\n",
        "    train_images = np.concatenate((train_images, train_images_augmentation)).astype(\"float32\") / 255.0\n",
        "    train_labels = keras.utils.to_categorical(train_labels + train_labels, num_classes)\n",
        "else:\n",
        "    train_images = train_images.astype(\"float32\") / 255.0\n",
        "    train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
        "\n",
        "test_images = test_images.astype(\"float32\") / 255.0\n",
        "test_labels = keras.utils.to_categorical(test_labels, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Convolutional Neural Networks (CNN)\n",
        "\n",
        "Ref.\n",
        "\n",
        "[機器學習 - 神經網路 (多層感知機 Multilayer perceptron, MLP) 含倒傳遞 ( Backward propagation) 詳細推導](https://chih-sheng-huang821.medium.com/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF-%E5%A4%9A%E5%B1%A4%E6%84%9F%E7%9F%A5%E6%A9%9F-multilayer-perceptron-mlp-%E5%90%AB%E8%A9%B3%E7%B4%B0%E6%8E%A8%E5%B0%8E-ee4f3d5d1b41)\n",
        "\n",
        "[卷積神經網絡介紹(Convolutional Neural Network)](https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC5-1%E8%AC%9B-%E5%8D%B7%E7%A9%8D%E7%A5%9E%E7%B6%93%E7%B6%B2%E7%B5%A1%E4%BB%8B%E7%B4%B9-convolutional-neural-network-4f8249d65d4f)\n",
        "\n",
        "![CNN Arch](./images/cnn-arch.png)\n",
        "\n",
        "Code ref.\n",
        "\n",
        "僅參考，因為程式碼需要調整\n",
        "[Step-by-Step Guide to Build CNN Model with Tensorflow](https://www.aitude.com/step-by-step-guide-to-build-cnn-model-with-tensorflow/)\n",
        "\n",
        "非常有幫助\n",
        "[Simple Cifar10 CNN Keras code with 88% Accuracy](https://www.kaggle.com/code/ektasharma/simple-cifar10-cnn-keras-code-with-88-accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build a custom CNN model using keras.Model subclassing\n",
        "\n",
        "\n",
        "class CNN(keras.Model):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Batch normalization (BN): https://medium.com/ching-i/batch-normalization-%E4%BB%8B%E7%B4%B9-135a24928f12\n",
        "        # 對每一個 mini-batch 都進行正規化到平均值為0、標準差為1的常態分佈\n",
        "        # * 減緩梯度消失\n",
        "        # * 解決 Internal Covariate Shift (ICS) 的問題\n",
        "\n",
        "        # Dropout: https://medium.com/%E6%89%8B%E5%AF%AB%E7%AD%86%E8%A8%98/%E4%BD%BF%E7%94%A8-tensorflow-%E4%BA%86%E8%A7%A3-dropout-bf64a6785431\n",
        "\n",
        "        self.cnn_layer_1 = layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")\n",
        "        self.batch_normalization_1 = layers.BatchNormalization()\n",
        "\n",
        "        self.cnn_layer_2 = layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")\n",
        "        self.batch_normalization_2 = layers.BatchNormalization()\n",
        "\n",
        "        self.pooling_1 = layers.MaxPooling2D((2, 2))\n",
        "        self.dropout_1 = layers.Dropout(0.3)\n",
        "\n",
        "        self.cnn_layer_3 = layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")\n",
        "        self.batch_normalization_3 = layers.BatchNormalization()\n",
        "\n",
        "        self.cnn_layer_4 = layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")\n",
        "        self.batch_normalization_4 = layers.BatchNormalization()\n",
        "\n",
        "        self.pooling_2 = layers.MaxPooling2D((2, 2))\n",
        "        self.dropout_2 = layers.Dropout(0.5)\n",
        "\n",
        "        self.cnn_layer_5 = layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")\n",
        "        self.batch_normalization_5 = layers.BatchNormalization()\n",
        "\n",
        "        self.cnn_layer_6 = layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")\n",
        "        self.batch_normalization_6 = layers.BatchNormalization()\n",
        "\n",
        "        self.pooling_3 = layers.MaxPooling2D((2, 2))\n",
        "        self.dropout_3 = layers.Dropout(0.5)\n",
        "\n",
        "        self.flatten = layers.Flatten()\n",
        "\n",
        "        self.first_dense_layer = layers.Dense(64, activation=\"relu\")\n",
        "\n",
        "        self.dense_batch_normalization = layers.BatchNormalization()\n",
        "        self.dense_dropout = layers.Dropout(0.5)\n",
        "\n",
        "        self.second_dense_layer = layers.Dense(10, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "\n",
        "        x = self.cnn_layer_1(inputs, training=training)\n",
        "        x = self.batch_normalization_1(x, training=training)\n",
        "\n",
        "        x = self.cnn_layer_2(x, training=training)\n",
        "        x = self.batch_normalization_2(x)\n",
        "\n",
        "        x = self.pooling_1(x)\n",
        "        x = self.dropout_1(x)\n",
        "\n",
        "        x = self.cnn_layer_3(x, training=training)\n",
        "        x = self.batch_normalization_3(x, training=training)\n",
        "\n",
        "        x = self.cnn_layer_4(x, training=training)\n",
        "        x = self.batch_normalization_4(x)\n",
        "\n",
        "        x = self.pooling_2(x)\n",
        "        x = self.dropout_2(x)\n",
        "\n",
        "        x = self.cnn_layer_5(x, training=training)\n",
        "        x = self.batch_normalization_5(x, training=training)\n",
        "\n",
        "        x = self.cnn_layer_6(x, training=training)\n",
        "        x = self.batch_normalization_6(x)\n",
        "\n",
        "        x = self.pooling_3(x)\n",
        "        x = self.dropout_3(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = self.first_dense_layer(x, training=training)\n",
        "\n",
        "        x = self.dense_batch_normalization(x, training=training)\n",
        "        x = self.dense_dropout(x)\n",
        "\n",
        "        x = self.second_dense_layer(x, training=training)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn_model = CNN()\n",
        "cnn_model.call(layers.Input((32, 32, 3)))\n",
        "cnn_model.build(input_shape=(None, 32, 32, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn_model.compile(\n",
        "    loss=keras.losses.categorical_crossentropy,\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_history = cnn_model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=num_epochs,\n",
        "    verbose=0,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=validation_split,\n",
        "    callbacks=[TqdmCallback(verbose=0)],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if training:\n",
        "    plt.figure(figsize=[6, 4])\n",
        "    plt.plot(train_history.history[\"loss\"], \"black\", linewidth=2.0)\n",
        "    plt.plot(train_history.history[\"val_loss\"], \"green\", linewidth=2.0)\n",
        "    plt.legend([\"Training Loss\", \"Validation Loss\"], fontsize=14)\n",
        "    plt.xlabel(\"Epochs\", fontsize=10)\n",
        "    plt.ylabel(\"Loss\", fontsize=10)\n",
        "    plt.title(\"Loss Curves\", fontsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if training:\n",
        "    plt.figure(figsize=[6, 4])\n",
        "    plt.plot(train_history.history[\"accuracy\"], \"black\", linewidth=2.0)\n",
        "    plt.plot(train_history.history[\"val_accuracy\"], \"blue\", linewidth=2.0)\n",
        "    plt.legend([\"Training Accuracy\", \"Validation Accuracy\"], fontsize=14)\n",
        "    plt.xlabel(\"Epochs\", fontsize=10)\n",
        "    plt.ylabel(\"Accuracy\", fontsize=10)\n",
        "    plt.title(\"Accuracy Curves\", fontsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# final => accuracy: 0.8728 - loss: 0.4241\n",
        "\n",
        "if not training:\n",
        "    test_result = cnn_model.evaluate(test_images, test_labels, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open(\"cifar10-cnn-outputs/\" + output_filename, \"w\")\n",
        "\n",
        "print(\"batch_size: \".ljust(20), batch_size, file=f)\n",
        "print(\"learning_rate: \".ljust(20), learning_rate, file=f)\n",
        "print(\"num_epochs: \".ljust(20), num_epochs, file=f)\n",
        "print(\"num_classes: \".ljust(20), num_classes, file=f)\n",
        "print(\"validation_split: \".ljust(20), validation_split, file=f)\n",
        "print(\"training accuracy: \".ljust(20), np.max(train_history.history[\"accuracy\"]), file=f)\n",
        "print(\"training loss: \".ljust(20), np.min(train_history.history[\"loss\"]), file=f)\n",
        "\n",
        "if training:\n",
        "    print(\"validation accuracy: \".ljust(20), np.max(train_history.history[\"val_accuracy\"]), file=f)\n",
        "    print(\"validation loss: \".ljust(20), np.min(train_history.history[\"val_loss\"]), file=f)\n",
        "\n",
        "print(\"feature: \".ljust(20), feature, file=f)\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "keras.models.save_model(cnn_model, \"./models/cifar10-cnn-{0}\".format(version), save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"./models/cifar10-cnn-{0}-history\".format(version), \"wb\") as f:\n",
        "    pickle.dump(train_history.history, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert not training, \"Training mode can't do final prediction\"\n",
        "\n",
        "cnn_final_model = keras.models.load_model(\"./models/cifar10-cnn-{0}\".format(version), custom_objects={\"CNN\": CNN})\n",
        "\n",
        "pred = cnn_final_model.predict(test_images)\n",
        "pred_labels = np.argmax(pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(5, 5, figsize=(15, 15))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in np.arange(0, 25):\n",
        "    axes[i].imshow(test_images[i])\n",
        "    axes[i].set_title(\"True: %s \\nPredict: %s\" % (class_names[np.argmax(test_labels[i])], class_names[pred_labels[i]]))\n",
        "    axes[i].axis(\"off\")\n",
        "    plt.subplots_adjust(wspace=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test result insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "confusion_metrics = metrics.confusion_matrix(np.argmax(test_labels, axis=1), pred_labels)\n",
        "display = metrics.ConfusionMatrixDisplay(confusion_metrics, display_labels=class_names)\n",
        "fig, axes = plt.subplots(figsize=(20, 10))\n",
        "display.plot(ax=axes)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(metrics.classification_report(np.argmax(test_labels, axis=1), pred_labels, target_names=class_names))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
